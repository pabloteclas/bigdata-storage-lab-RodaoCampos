# bigdata-storage-lab-RodaoCampos
# De CSVs heterog√©neos a un almac√©n anal√≠tico confiable  
**Laboratorio T√©cnico ‚Äî `bigdata-storage-lab-<apellido>`**

---

## 1. Objetivo

El prop√≥sito de este laboratorio es **dise√±ar e implementar un flujo completo de ingesta, validaci√≥n y normalizaci√≥n de datos heterog√©neos en CSV** para consolidarlos en un **almac√©n anal√≠tico confiable**.  

La secuencia de trabajo ser√°:

1. **Ingesta:** lectura y almacenamiento inicial de m√∫ltiples CSV (estructuras dispares, columnas faltantes, diferentes codificaciones/formatos).  
2. **Validaci√≥n:** aplicaci√≥n de reglas de calidad (tipos de datos, valores nulos, rangos v√°lidos, duplicados).  
3. **Normalizaci√≥n:** unificaci√≥n de esquemas, tipos de datos y claves de integraci√≥n.  
4. **Zonas de almacenamiento (Medallion Architecture):**  
   - **Bronze:** datos crudos tal como se ingieren.  
   - **Silver:** datos limpios y normalizados.  
   - **Gold:** modelos listos para anal√≠tica y generaci√≥n de KPIs.  
5. **KPIs:** c√°lculo de m√©tricas simples a partir de los datos consolidados (ej. volumen total de registros v√°lidos, % de errores, tendencias agregadas).

---

## 2. Entregables

- **Repositorio GitHub p√∫blico (`bigdata-storage-lab-<apellido>`):**  
  - C√≥digo fuente (Python/SQL/ETL).  
  - Scripts/notebooks de validaci√≥n y normalizaci√≥n.  
  - Estructura de carpetas clara (bronze/silver/gold).  
  - Documentaci√≥n (`README.md`, diagramas, instrucciones de ejecuci√≥n).  

- **Aplicaci√≥n Streamlit:**  
  - Dashboard que muestre KPIs y permita navegar los datos en las diferentes capas.  
  - Visualizaciones b√°sicas (tablas, gr√°ficos de barras/l√≠neas/pastel seg√∫n pertinencia).  

---

## 3. Criterios de Evaluaci√≥n

1. **Dise√±o y justificaci√≥n:**  
   - Claridad en la arquitectura propuesta y sus decisiones.  
   - Uso de buenas pr√°cticas (nombres consistentes, modularidad).  

2. **Calidad de los datos:**  
   - Aplicaci√≥n de validaciones relevantes y registro de errores.  
   - Nivel de limpieza y consistencia logrado en Silver/Gold.  

3. **Trazabilidad y modelo de almac√©n de datos:**  
   - Evidencia de flujo claro Bronze ‚Üí Silver ‚Üí Gold.  
   - Capacidad de reconstruir pasos de transformaci√≥n.  

4. **Documentaci√≥n:**  
   - Instrucciones reproducibles (setup, dependencias, ejecuci√≥n).  
   - Breve memoria t√©cnica justificando decisiones.  

---

## 4. Qu√© **NO** subir

- **Datos sensibles, confidenciales o con informaci√≥n personal identificable (PII).**  
- Archivos CSV reales de empresas/instituciones.  
- Claves de acceso, contrase√±as, tokens o credenciales en el repo o app.  

*(Se recomienda generar datos sint√©ticos o usar datasets p√∫blicos abiertos.)*

---

## 5. Tiempo estimado por fase

| Fase                        | Tiempo estimado |
|-----------------------------|-----------------|
| Ingesta de CSVs             | 2 h             |
| Validaci√≥n de calidad       | 3 h             |
| Normalizaci√≥n y esquemas    | 4 h             |
| Dise√±o Bronze/Silver/Gold   | 3 h             |
| Desarrollo de KPIs          | 3 h             |
| Implementaci√≥n en Streamlit | 3 h             |
| Documentaci√≥n final         | 2 h             |
| **Total aproximado**        | **20 h**        |

---

üìå **Entrega final:** subir el repo en GitHub p√∫blico (`bigdata-storage-lab-<apellido>`) e incluir el link a la app de Streamlit desplegada.
