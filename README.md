# bigdata-storage-lab-RodaoCampos
# De CSVs heterog√©neos a un almac√©n anal√≠tico confiable  
**Laboratorio T√©cnico ‚Äî `bigdata-storage-lab-<apellido>`**

---

## 1. Objetivo

El prop√≥sito de este laboratorio es **dise√±ar e implementar un flujo completo de ingesta, validaci√≥n y normalizaci√≥n de datos heterog√©neos en CSV** para consolidarlos en un **almac√©n anal√≠tico confiable**.  

La secuencia de trabajo ser√°:

1. **Ingesta:** lectura y almacenamiento inicial de m√∫ltiples CSV (estructuras dispares, columnas faltantes, diferentes codificaciones/formatos).  
2. **Validaci√≥n:** aplicaci√≥n de reglas de calidad (tipos de datos, valores nulos, rangos v√°lidos, duplicados).  
3. **Normalizaci√≥n:** unificaci√≥n de esquemas, tipos de datos y claves de integraci√≥n.  
4. **Zonas de almacenamiento (Medallion Architecture):**  
   - **Bronze:** datos crudos tal como se ingieren.  
   - **Silver:** datos limpios y normalizados.  
   - **Gold:** modelos listos para anal√≠tica y generaci√≥n de KPIs.  
5. **KPIs:** c√°lculo de m√©tricas simples a partir de los datos consolidados (ej. volumen total de registros v√°lidos, % de errores, tendencias agregadas).

---

## 2. Entregables

- **Repositorio GitHub p√∫blico (`bigdata-storage-lab-<apellido>`):**  
  - C√≥digo fuente (Python/SQL/ETL).  
  - Scripts/notebooks de validaci√≥n y normalizaci√≥n.  
  - Estructura de carpetas clara (bronze/silver/gold).  
  - Documentaci√≥n (`README.md`, diagramas, instrucciones de ejecuci√≥n).  

- **Aplicaci√≥n Streamlit:**  
  - Dashboard que muestre KPIs y permita navegar los datos en las diferentes capas.  
  - Visualizaciones b√°sicas (tablas, gr√°ficos de barras/l√≠neas/pastel seg√∫n pertinencia).  

---

## 3. Criterios de Evaluaci√≥n

1. **Dise√±o y justificaci√≥n:**  
   - Claridad en la arquitectura propuesta y sus decisiones.  
   - Uso de buenas pr√°cticas (nombres consistentes, modularidad).  

2. **Calidad de los datos:**  
   - Aplicaci√≥n de validaciones relevantes y registro de errores.  
   - Nivel de limpieza y consistencia logrado en Silver/Gold.  

3. **Trazabilidad y modelo de almac√©n de datos:**  
   - Evidencia de flujo claro Bronze ‚Üí Silver ‚Üí Gold.  
   - Capacidad de reconstruir pasos de transformaci√≥n.  

4. **Documentaci√≥n:**  
   - Instrucciones reproducibles (setup, dependencias, ejecuci√≥n).  
   - Breve memoria t√©cnica justificando decisiones.  

---

## 4. Qu√© **NO** subir

- **Datos sensibles, confidenciales o con informaci√≥n personal identificable (PII).**  
- Archivos CSV reales de empresas/instituciones.  
- Claves de acceso, contrase√±as, tokens o credenciales en el repo o app.  

*(Se recomienda generar datos sint√©ticos o usar datasets p√∫blicos abiertos.)*

---

## 5. Tiempo estimado por fase

| Fase                        | Tiempo estimado |
|-----------------------------|-----------------|
| Ingesta de CSVs             | 2 h             |
| Validaci√≥n de calidad       | 3 h             |
| Normalizaci√≥n y esquemas    | 4 h             |
| Dise√±o Bronze/Silver/Gold   | 3 h             |
| Desarrollo de KPIs          | 3 h             |
| Implementaci√≥n en Streamlit | 3 h             |
| Documentaci√≥n final         | 2 h             |
| **Total aproximado**        | **20 h**        |

---

üìå **Entrega final:** subir el repo en GitHub p√∫blico (`bigdata-storage-lab-<apellido>`) e incluir el link a la app de Streamlit desplegada.

## üöÄ Pega y corre ‚Äî Gu√≠a r√°pida de entrega

### Pasos m√≠nimos (en orden)

1. **Crear repositorio con estructura**  
   - Nombre: `bigdata-storage-lab-<apellido>`.  
   - Crear carpetas (`src`, `data/raw`, `data/bronze`, `data/silver`, `data/gold`, `docs`, `tests`).  
   - Tiempo estimado: **20 min**.  
   - ‚úîÔ∏è Verificar: que todas las carpetas aparecen en GitHub con `.gitkeep`.

2. **Pegar archivos base**  
   - Subir `ingest.py`, `validate.py`, `transform.py`, `streamlit_app.py`, `requirements.txt`.  
   - Tiempo estimado: **30 min**.  
   - ‚úîÔ∏è Verificar: el repo abre bien los archivos y no hay errores de sintaxis al ejecutar `streamlit run streamlit_app.py` en local.

3. **Subir CSVs de prueba a `/data/raw/`**  
   - Usar datasets sint√©ticos (ej. ventas, IoT, fraude).  
   - Tiempo estimado: **15 min**.  
   - ‚úîÔ∏è Verificar: que la app procesa al menos 2‚Äì3 archivos distintos y genera Bronze + Silver.

4. **Desplegar en Streamlit Community Cloud**  
   - Conectar el repo, elegir `streamlit_app.py` como archivo principal.  
   - Tiempo estimado: **30 min**.  
   - ‚úîÔ∏è Verificar: la URL abre y se pueden subir CSVs desde el navegador.

5. **Completar README con reflexiones**  
   - A√±adir secci√≥n ‚Äúüìù Prompts de reflexi√≥n‚Äù y responder los 5 puntos.  
   - Tiempo estimado: **20 min**.  
   - ‚úîÔ∏è Verificar: README tiene arquitectura, justificaci√≥n (5V), checklist, capturas en `docs/`.

6. **Entregar URLs**  
   - **Repo p√∫blico en GitHub.**  
   - **URL de la app en Streamlit.**  
   - Tiempo estimado: **5 min**.  
   - ‚úîÔ∏è Verificar: ambos links son accesibles sin credenciales.

---

### ‚è±Ô∏è Tiempo total estimado: **~2 h**

### ‚úÖ Checklist final antes de entregar
- [ ] URL de Streamlit funcional.  
- [ ] `bronze.csv` y `silver.csv` generados en `/data`.  
- [ ] README con decisiones justificadas + reflexiones respondidas.  
- [ ] Diccionario y gobernanza completos en `docs/`.  
- [ ] Capturas de pantallas del dashboard incluidas.  
- [ ] Tests/checklist.md marcado.  

